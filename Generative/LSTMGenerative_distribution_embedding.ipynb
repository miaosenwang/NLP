{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 6925\n"
     ]
    }
   ],
   "source": [
    "# load text file into memory\n",
    "#file = open('C:\\\\Code\\\\Data\\\\Books\\\\story.txt')\n",
    "file = open('..\\\\..\\\\Data\\\\Books\\\\sherlock.txt')\n",
    "MAX_NB_WORDS = 1000\n",
    "textSource = ['BOL ' + line + ' EOL' for line in sent_tokenize(file.read().lower().replace('\\n', ' '))]\n",
    " \n",
    "\n",
    "file.close()\n",
    "print('corpus length:', len(textSource))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"BOL ï»¿project gutenberg's the adventures of sherlock holmes, by arthur conan doyle  this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. EOL\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textSource[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences count: 6925\n",
      "vocab size: 8467\n"
     ]
    }
   ],
   "source": [
    "# tokenize words and convert word sequence to digit sequence\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(textSource)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(textSource)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) +1\n",
    "\n",
    "# build a reverse look up: index -> word\n",
    "index_word = dict()\n",
    "for k,v in word_index.items():\n",
    "    if not v in index_word:\n",
    "        index_word[v] = k\n",
    "        \n",
    "print('sentences count:', len(sequences))\n",
    "print('vocab size:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sequences count: 90344\n",
      "longest training sentence 83\n"
     ]
    }
   ],
   "source": [
    "# build the training data by creating context-> next word paris. by shiftting x number of word per pair\n",
    "\n",
    "min_length = 1\n",
    "sentences = []\n",
    "next_words = []\n",
    "for i in range(0, len(sequences)):\n",
    "    for j in range(min_length, len(sequences[i])-1): \n",
    "        sentences.append(sequences[i][0: j])\n",
    "        next_words.append(sequences[i][j+1])\n",
    "\n",
    "print('training sequences count:', len(sentences))\n",
    "print('longest training sentence', len( max(sentences, key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build training data\n",
    "X = pad_sequences(sentences)\n",
    "y = np.zeros((len(sentences), vocab_size), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    y[i, next_words[i]] = 1\n",
    "\n",
    "sent_length = len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=sent_length))\n",
    "model.add(LSTM(256, dropout= 0.2))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    exp_preds = np.exp(np.log(preds))\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(5, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_word(input, count, word_num):\n",
    "    input[0][count] = word_num\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_sent(model):\n",
    "    input = np.zeros((1, sent_length), dtype=np.float32)\n",
    "    message = 'sherlock holmes'\n",
    "    count =0\n",
    "    append_word(input, count, word_index['bol'])\n",
    "    append_word(input, count, word_index['sherlock'])\n",
    "    append_word(input, count, word_index['holmes'])\n",
    "    \n",
    "    for i in range(0, 10):\n",
    "        predict = model.predict(input)[0]\n",
    "        next = sample(predict)\n",
    "\n",
    "        input[0][count] = next\n",
    "        count += 1\n",
    "        \n",
    "        message += ' '\n",
    "        message += index_word[next]\n",
    "        \n",
    "        # start a new sentence when the current one ends\n",
    "        if index_word[next] == 'eol':\n",
    "            append_word(input, count, word_index['bol'])\n",
    "            message += ' bol'\n",
    "\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/5\n",
      "90344/90344 [==============================] - 496s - loss: 7.6576   \n",
      "Epoch 2/5\n",
      "90344/90344 [==============================] - 478s - loss: 7.6303   \n",
      "Epoch 3/5\n",
      "90344/90344 [==============================] - 458s - loss: 7.6298   \n",
      "Epoch 4/5\n",
      "90344/90344 [==============================] - 494s - loss: 7.6302   \n",
      "Epoch 5/5\n",
      "90344/90344 [==============================] - 494s - loss: 7.6320   \n",
      "sherlock holmes the\n",
      "sherlock holmes the out\n",
      "sherlock holmes the out eol bol\n",
      "sherlock holmes the out eol bol eol bol\n",
      "sherlock holmes the out eol bol eol bol i\n",
      "sherlock holmes the out eol bol eol bol i eol bol\n",
      "sherlock holmes the out eol bol eol bol i eol bol eol bol\n",
      "sherlock holmes the out eol bol eol bol i eol bol eol bol eol bol\n",
      "sherlock holmes the out eol bol eol bol i eol bol eol bol eol bol the\n",
      "sherlock holmes the out eol bol eol bol i eol bol eol bol eol bol the eol bol\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/5\n",
      "90344/90344 [==============================] - 497s - loss: 7.6316   \n",
      "Epoch 2/5\n",
      "90344/90344 [==============================] - 500s - loss: 7.6317   \n",
      "Epoch 3/5\n",
      "90344/90344 [==============================] - 497s - loss: 7.6365   \n",
      "Epoch 4/5\n",
      "90344/90344 [==============================] - 520s - loss: 7.6356   \n",
      "Epoch 5/5\n",
      "90344/90344 [==============================] - 487s - loss: 7.6368   \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "sum(pvals[:-1]) > 1.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-06c59b55c962>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mgenerate_sent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m#model.save('StoryModel.model')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-d009bf9be07c>\u001b[0m in \u001b[0;36mgenerate_sent\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mnext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-949c52912b77>\u001b[0m in \u001b[0;36msample\u001b[1;34m(preds)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprobas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.multinomial (numpy\\random\\mtrand\\mtrand.c:37541)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: sum(pvals[:-1]) > 1.0"
     ]
    }
   ],
   "source": [
    "for iteration in range(1, 10):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X, y, batch_size=256, epochs=5)\n",
    "    \n",
    "    generate_sent(model)\n",
    "#model.save('StoryModel.model')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
